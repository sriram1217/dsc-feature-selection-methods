{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Methods\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you'll learn about the different techniques you can use to only use features that are most relevant to your model.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Use feature selection to obtain the optimal subset of features in a dataset \n",
    "- Identify when it is appropriate to use certain methods of feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature selection is the process by which you **select a subset of features** relevant for model construction. Feature selection comes with several benefits, the most obvious being the improvement in performance of a machine learning algorithm. Other benefits include:\n",
    "\n",
    "* Decrease in computational complexity: As the number of features is reduced in a model, the easier it will be to compute the parameters of your model. It will also mean a decrease in the amount of data storage required to maintain the features of your model \n",
    "* Understanding your data: In the process of feature selection, you will potentially gain more understanding of how features relate to one another \n",
    "\n",
    "Now, let's look at the different types of feature selection approaches and their advantages/disadvantages.\n",
    "\n",
    "### Types of Feature Selection\n",
    "\n",
    "Like many things in data science, there is no clear and easy answer for deciding which features to include in a model. There are, however, different strategies you can use to process features in an efficient way: \n",
    "\n",
    "* Domain knowledge\n",
    "* Filter methods\n",
    "* Wrapper methods\n",
    "* Embedded methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain Knowledge   \n",
    "\n",
    "One of the most important aspects when determining important features is the knowledge of the specific domain related to your dataset. This might mean reading past research papers that have explored similar topics or asking key stakeholders to determine what they believe the most important factors are for predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Methods \n",
    "\n",
    "Filter methods are feature selection methods carried out as a preprocessing step before even running a model. Filter methods work by observing characteristics of how variables are related to one another. Depending on the model that is being used, different metrics are used to determine which features will get eliminated and which will remain. Typically, filter methods will return a \"feature ranking\" that will tell you how features are ordered in relation to one another. They will remove the variables that are considered redundant. It's up to the data scientist to determine the cut-off point at which they will keep the top $n$ features, and this $n$ is usually determined through cross-validation.\n",
    "\n",
    "<img src= \"./images/new_filter.png\">\n",
    "\n",
    "In the linear regression context, a common filter method is to eliminate features that are highly **correlated** with one another.\n",
    "\n",
    "Another method is to use a ***variance threshold***. This sets some threshold of required variance among features in order to include them in a model. The thought process behind this is that if variables do not have a high variance, they will not change much and will therefore not have much impact on our dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper Methods   \n",
    "\n",
    "Wrapper methods determine the optimal subset of features using different combinations of features to train models and then calculating performance. Every subset is used to train models and then evaluated on a test set. As you might imagine, wrapper methods can end up being very computationally intensive, however, they are highly effective in determining the optimal subset. Because wrapper methods are so time-consuming, it becomes challenging to use them with large feature sets. \n",
    "\n",
    "<img src = \"./images/new_wrapper.png\">\n",
    "\n",
    "An example of a wrapper method in linear regression is ***recursive feature elimination***, which starts with all features included in a model and removes them one by one. After the model has had a feature removed, whichever subset of features resulted in the least significant deterioration of the model fit will indicate which omitted feature is the least useful for prediction.\n",
    "\n",
    "The opposite of this process is ***forward selection***, which undergoes the same process in reverse. It begins with a single feature and continues to add the one feature at a time that improves model performance the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedded Methods \n",
    "\n",
    "Embedded methods are feature selection methods that are included within the actual formulation of your machine learning algorithm. The most common kind of embedded method is regularization, in particular lasso regression, because it has the capability of reducing your set of features automatically.\n",
    "\n",
    "<img src = \"./images/new_embedded.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection in Action\n",
    "\n",
    "Now, we're going to review the process behind performing feature selection with a dataset pertaining to diabetes. The dataset contains the independent variables age, sex, body mass index, blood pressure, and 6 different blood serum measurements. The target variable represents a quantitative measurement progression of diabetes from one year after a baseline observation. With feature selection, our goal is to find a model that is able to maintain high accuracy while not overfitting to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data\n",
    "\n",
    "To begin with, we are going to load the necessary libraries and functions, load the data, and create a dummy variable for the variable `'SEX'`. The target variable is in the column `'Y'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import (VarianceThreshold, SelectKBest, f_regression, mutual_info_regression, \n",
    "    RFE, RFECV)\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('diabetes.tab.txt', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the target and features from the DataFrame\n",
    "target = df['Y']\n",
    "features = df.drop(columns='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=20, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variable for sex\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "train_female = ohe.fit_transform(X_train[['SEX']]).flatten()\n",
    "test_female = ohe.transform(X_test[['SEX']]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both regularization (an embedded method) and various filters, it is important to standardize the data. This next cell is fitting a `StandardScaler` from `sklearn` to the training data and using it to transform all of the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.433522</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>-0.967597</td>\n",
       "      <td>-2.067847</td>\n",
       "      <td>-1.623215</td>\n",
       "      <td>-1.280312</td>\n",
       "      <td>-0.347527</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-1.095555</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1.117754</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>-0.516691</td>\n",
       "      <td>1.142458</td>\n",
       "      <td>-0.168101</td>\n",
       "      <td>-0.129601</td>\n",
       "      <td>-0.424950</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>0.543382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1.350445</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>1.850570</td>\n",
       "      <td>1.427819</td>\n",
       "      <td>0.413945</td>\n",
       "      <td>0.764667</td>\n",
       "      <td>-1.044334</td>\n",
       "      <td>1.454710</td>\n",
       "      <td>0.597504</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.511086</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>-1.373413</td>\n",
       "      <td>-1.711146</td>\n",
       "      <td>-0.837453</td>\n",
       "      <td>-1.148802</td>\n",
       "      <td>1.278358</td>\n",
       "      <td>-1.622013</td>\n",
       "      <td>-0.796071</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>-0.743778</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>-0.141664</td>\n",
       "      <td>-1.565010</td>\n",
       "      <td>-1.339491</td>\n",
       "      <td>-0.115257</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-0.970101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-0.898905</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>-1.373413</td>\n",
       "      <td>-0.855065</td>\n",
       "      <td>-0.138998</td>\n",
       "      <td>0.278080</td>\n",
       "      <td>-0.889488</td>\n",
       "      <td>0.685530</td>\n",
       "      <td>0.130301</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1.583137</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>1.782934</td>\n",
       "      <td>1.285138</td>\n",
       "      <td>0.297536</td>\n",
       "      <td>0.251778</td>\n",
       "      <td>0.349281</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>0.113090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-2.139926</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>-0.494145</td>\n",
       "      <td>-1.354445</td>\n",
       "      <td>-1.244885</td>\n",
       "      <td>-1.286887</td>\n",
       "      <td>0.271858</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-0.397142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.807499</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>0.182215</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>-0.924760</td>\n",
       "      <td>-0.464951</td>\n",
       "      <td>-0.812065</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>-0.397142</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-1.596980</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>-0.201056</td>\n",
       "      <td>0.286377</td>\n",
       "      <td>-0.808351</td>\n",
       "      <td>-0.478102</td>\n",
       "      <td>-0.270103</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>-0.714602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "171 -0.433522 -0.947549 -0.967597 -2.067847 -1.623215 -1.280312 -0.347527   \n",
       "388  1.117754  1.055354 -0.516691  1.142458 -0.168101 -0.129601 -0.424950   \n",
       "268  1.350445  1.055354  1.850570  1.427819  0.413945  0.764667 -1.044334   \n",
       "31  -0.511086 -0.947549 -1.373413 -1.711146 -0.837453 -1.148802  1.278358   \n",
       "427 -0.743778  1.055354  0.114579 -0.141664 -1.565010 -1.339491 -0.115257   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "218 -0.898905 -0.947549 -1.373413 -0.855065 -0.138998  0.278080 -0.889488   \n",
       "412  1.583137 -0.947549  1.782934  1.285138  0.297536  0.251778  0.349281   \n",
       "223 -2.139926 -0.947549 -0.494145 -1.354445 -1.244885 -1.286887  0.271858   \n",
       "271  0.807499  1.055354  0.182215  0.857098 -0.924760 -0.464951 -0.812065   \n",
       "355 -1.596980  1.055354 -0.201056  0.286377 -0.808351 -0.478102 -0.270103   \n",
       "\n",
       "           S4        S5  female  \n",
       "171 -0.852832 -1.095555     0.0  \n",
       "388 -0.083651  0.543382     1.0  \n",
       "268  1.454710  0.597504     1.0  \n",
       "31  -1.622013 -0.796071     0.0  \n",
       "427 -0.852832 -0.970101     1.0  \n",
       "..        ...       ...     ...  \n",
       "218  0.685530  0.130301     0.0  \n",
       "412 -0.083651  0.113090     0.0  \n",
       "223 -0.852832 -0.397142     0.0  \n",
       "271 -0.083651 -0.397142     1.0  \n",
       "355 -0.083651 -0.714602     1.0  \n",
       "\n",
       "[353 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale every feature except the binary column - female\n",
    "transformed_training_features = scaler.fit_transform(X_train.iloc[:,:-1])\n",
    "transformed_testing_features = scaler.transform(X_test.iloc[:,:-1])\n",
    "\n",
    "# Convert the scaled features into a DataFrame\n",
    "X_train_transformed = pd.DataFrame(scaler.transform(X_train.iloc[:,:-1]), \n",
    "                                   columns=X_train.columns[:-1], \n",
    "                                   index=X_train.index)\n",
    "X_test_transformed = pd.DataFrame(scaler.transform(X_test.iloc[:,:-1]), \n",
    "                                  columns=X_train.columns[:-1], \n",
    "                                  index=X_test.index)\n",
    "\n",
    "# Add binary column back in\n",
    "X_train_transformed['female'] = train_female\n",
    "X_test_transformed['female'] = test_female\n",
    "\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>female</th>\n",
       "      <th>...</th>\n",
       "      <th>S3^2</th>\n",
       "      <th>S3 S4</th>\n",
       "      <th>S3 S5</th>\n",
       "      <th>S3 female</th>\n",
       "      <th>S4^2</th>\n",
       "      <th>S4 S5</th>\n",
       "      <th>S4 female</th>\n",
       "      <th>S5^2</th>\n",
       "      <th>S5 female</th>\n",
       "      <th>female^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433522</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>-0.967597</td>\n",
       "      <td>-2.067847</td>\n",
       "      <td>-1.623215</td>\n",
       "      <td>-1.280312</td>\n",
       "      <td>-0.347527</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-1.095555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120775</td>\n",
       "      <td>0.296382</td>\n",
       "      <td>0.380734</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.727322</td>\n",
       "      <td>0.934324</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.200240</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.117754</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>-0.516691</td>\n",
       "      <td>1.142458</td>\n",
       "      <td>-0.168101</td>\n",
       "      <td>-0.129601</td>\n",
       "      <td>-0.424950</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>0.543382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180582</td>\n",
       "      <td>0.035548</td>\n",
       "      <td>-0.230910</td>\n",
       "      <td>-0.424950</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>-0.045455</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>0.295264</td>\n",
       "      <td>0.543382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.350445</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>1.850570</td>\n",
       "      <td>1.427819</td>\n",
       "      <td>0.413945</td>\n",
       "      <td>0.764667</td>\n",
       "      <td>-1.044334</td>\n",
       "      <td>1.454710</td>\n",
       "      <td>0.597504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090634</td>\n",
       "      <td>-1.519204</td>\n",
       "      <td>-0.623994</td>\n",
       "      <td>-1.044334</td>\n",
       "      <td>2.116182</td>\n",
       "      <td>0.869195</td>\n",
       "      <td>1.454710</td>\n",
       "      <td>0.357011</td>\n",
       "      <td>0.597504</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511086</td>\n",
       "      <td>-0.947549</td>\n",
       "      <td>-1.373413</td>\n",
       "      <td>-1.711146</td>\n",
       "      <td>-0.837453</td>\n",
       "      <td>-1.148802</td>\n",
       "      <td>1.278358</td>\n",
       "      <td>-1.622013</td>\n",
       "      <td>-0.796071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.634199</td>\n",
       "      <td>-2.073513</td>\n",
       "      <td>-1.017664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.630925</td>\n",
       "      <td>1.291237</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.633729</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.743778</td>\n",
       "      <td>1.055354</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>-0.141664</td>\n",
       "      <td>-1.565010</td>\n",
       "      <td>-1.339491</td>\n",
       "      <td>-0.115257</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-0.970101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013284</td>\n",
       "      <td>0.098295</td>\n",
       "      <td>0.111811</td>\n",
       "      <td>-0.115257</td>\n",
       "      <td>0.727322</td>\n",
       "      <td>0.827333</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>0.941095</td>\n",
       "      <td>-0.970101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0 -0.433522 -0.947549 -0.967597 -2.067847 -1.623215 -1.280312 -0.347527   \n",
       "1  1.117754  1.055354 -0.516691  1.142458 -0.168101 -0.129601 -0.424950   \n",
       "2  1.350445  1.055354  1.850570  1.427819  0.413945  0.764667 -1.044334   \n",
       "3 -0.511086 -0.947549 -1.373413 -1.711146 -0.837453 -1.148802  1.278358   \n",
       "4 -0.743778  1.055354  0.114579 -0.141664 -1.565010 -1.339491 -0.115257   \n",
       "\n",
       "         S4        S5  female  ...      S3^2     S3 S4     S3 S5  S3 female  \\\n",
       "0 -0.852832 -1.095555     0.0  ...  0.120775  0.296382  0.380734  -0.000000   \n",
       "1 -0.083651  0.543382     1.0  ...  0.180582  0.035548 -0.230910  -0.424950   \n",
       "2  1.454710  0.597504     1.0  ...  1.090634 -1.519204 -0.623994  -1.044334   \n",
       "3 -1.622013 -0.796071     0.0  ...  1.634199 -2.073513 -1.017664   0.000000   \n",
       "4 -0.852832 -0.970101     1.0  ...  0.013284  0.098295  0.111811  -0.115257   \n",
       "\n",
       "       S4^2     S4 S5  S4 female      S5^2  S5 female  female^2  \n",
       "0  0.727322  0.934324  -0.000000  1.200240  -0.000000       0.0  \n",
       "1  0.006998 -0.045455  -0.083651  0.295264   0.543382       1.0  \n",
       "2  2.116182  0.869195   1.454710  0.357011   0.597504       1.0  \n",
       "3  2.630925  1.291237  -0.000000  0.633729  -0.000000       0.0  \n",
       "4  0.727322  0.827333  -0.852832  0.941095  -0.970101       1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_poly_train = pd.DataFrame(poly.fit_transform(X_train_transformed),\n",
    "                            columns=poly.get_feature_names(X_train_transformed.columns))\n",
    "X_poly_test = pd.DataFrame(poly.transform(X_test_transformed),\n",
    "                           columns=poly.get_feature_names(X_test_transformed.columns))\n",
    "X_poly_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use `PolynomialFeatures` to transform the data and create interactions and squared terms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have 65 total columns! You can imagine that this model will greatly overfit to the data. Let's try it out with our training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Baseline Model Metrics\n",
    "\n",
    "Before we perform feature selection, we should see how well the baseline model performs. Because we are going to be running many different models here, we have created a function to ensure that we are following the D.R.Y. principle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, X_test, y_train, y_test, display=True):\n",
    "    \n",
    "    train_r2 = model.score(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_rmse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "    \n",
    "    test_r2 = model.score(X_test, y_test)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "    \n",
    "    if (display):\n",
    "        print('Training R^2:', train_r2)\n",
    "        print('Training Root Mean Squared Error:', train_rmse)\n",
    "        print('\\n----------------\\n')\n",
    "        print('Testing R^2:', test_r2)\n",
    "        print('Testing Root Mean Squared Error:', test_rmse)\n",
    "        \n",
    "    return test_r2, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.6129201570156093\n",
      "Training Root Mean Squared Error: 47.75689855370698\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.3601265020782821\n",
      "Testing Root Mean Squared Error: 61.69068199775078\n"
     ]
    }
   ],
   "source": [
    "lr_poly = LinearRegression()\n",
    "lr_poly.fit(X_poly_train, y_train)\n",
    "\n",
    "poly_r2, poly_rmse = run_model(lr_poly, X_poly_train, X_poly_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the model has fit very well to the training data, but it has fit to a lot of noise. It's time to get rid of some features to see if this improves the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Methods  \n",
    "\n",
    "Let's begin by trying out some filter methods for feature selection. The benefit of filter methods is that they can provide us with some useful visualizations for helping us gain an understanding about the characteristics of our data. To begin with, let's use a simple variance threshold to eliminate the features with low variance.\n",
    "\n",
    "### `VarianceThreshold`\n",
    "\n",
    "The `VarianceThreshold` class from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html)) works similarly to other preprocessing tools like `StandardScaler`. You fit it on the training data and transform both the train and test data, before fitting the model or making predictions.\n",
    "\n",
    "The default variance threshold is 0.0, meaning that `VarianceThreshold` will eliminate only features that have the same value in every row. This means that if you don't specify any parameters, there will be no difference in the features used for this particular dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.612994096887439\n",
      "Training Root Mean Squared Error: 47.75233708187187\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.3628269494240123\n",
      "Testing Root Mean Squared Error: 61.560368289112795\n",
      "\n",
      "----------------\n",
      "\n",
      "65 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "reduced_feature_train = pd.DataFrame(selector.fit_transform(X_poly_train), columns=X_poly_train.columns, index=X_poly_train.index)\n",
    "reduced_feature_test = pd.DataFrame(selector.transform(X_poly_test), columns=X_poly_test.columns, index=X_poly_test.index)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(reduced_feature_train, y_train)\n",
    "reduced_r2, reduced_rmse = run_model(lr, reduced_feature_train, reduced_feature_test, y_train, y_test)\n",
    "\n",
    "print('\\n----------------\\n')\n",
    "print(f\"{reduced_feature_train.shape[1]} out of {X_poly_train.shape[1]} features used\")\n",
    "print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "print('Reduced R-Squared: ', round(reduced_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try out some different variance thresholds to see how they impact the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44404269, 0.59910866, 0.75417464, 0.90924061, 1.06430658,\n",
       "       1.21937256, 1.37443853, 1.5295045 , 1.68457048, 1.83963645])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(np.percentile(selector.variances_,10), np.percentile(selector.variances_, 90), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance threshold: 0.44404268801979535\n",
      "58 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 0.5991086615890968\n",
      "53 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 0.7541746351583984\n",
      "53 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 0.9092406087276999\n",
      "45 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.41\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 1.0643065822970015\n",
      "14 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.04\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 1.2193725558663029\n",
      "13 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.03\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 1.3744385294356045\n",
      "10 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.07\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 1.529504503004906\n",
      "9 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.09\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 1.6845704765742076\n",
      "8 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.09\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Variance threshold: 1.8396364501435092\n",
      "7 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.05\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_ranges = np.linspace(np.percentile(selector.variances_,10), np.percentile(selector.variances_, 90), 10)\n",
    "reduced_r2s = []\n",
    "for thresh in threshold_ranges:\n",
    "    selector = VarianceThreshold(thresh)\n",
    "    reduced_feature_train = selector.fit_transform(X_poly_train)\n",
    "    reduced_feature_test = selector.transform(X_poly_test)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(reduced_feature_train, y_train)\n",
    "    reduced_r2, reduced_rmse = run_model(lr, reduced_feature_train, reduced_feature_test, y_train, y_test, display=False)\n",
    "    reduced_r2s.append(reduced_r2)\n",
    "    \n",
    "    print('Variance threshold:', thresh)\n",
    "    print(f\"{reduced_feature_train.shape[1]} out of {X_poly_train.shape[1]} features used\")\n",
    "    print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "    print('Reduced R-Squared: ', round(reduced_r2, 2))\n",
    "    print('\\n--------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(threshold_ranges, reduced_r2s, label=\"features reduced with VarianceThreshold\")\n",
    "ax.axhline(y=poly_r2, linestyle=\"--\", label=\"baseline\")\n",
    "ax.set_xlabel(\"Variance Threshold\")\n",
    "ax.set_ylabel(\"Test R-Squared\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that did not seem to eliminate the features very well. For some of the lower thresholds it only does a little better than the base polynomial. And for larger thresholds performance is much worse than baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SelectKBest`\n",
    "\n",
    "`SelectKBest` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)) works a little differently. Instead of just looking at the feature values, this transformer uses a particular statistic to compare features to the target one by one. Then it selects the top `k` features based on this statistic. The default `k` is 10.\n",
    "\n",
    "One statistic we can try is `f_regression` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.5272198197441764\n",
      "Training Root Mean Squared Error: 52.77952383154054\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.40576194869484794\n",
      "Testing Root Mean Squared Error: 59.45012044763017\n",
      "\n",
      "----------------\n",
      "\n",
      "10 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.41\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(score_func=f_regression)\n",
    "X_k_best_train = selector.fit_transform(X_poly_train, y_train)\n",
    "X_k_best_test = selector.transform(X_poly_test)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_k_best_train, y_train)\n",
    "k_best_r2, k_best_rmse = run_model(lr, X_k_best_train, X_k_best_test, y_train, y_test)\n",
    "\n",
    "print('\\n----------------\\n')\n",
    "print(f\"{X_k_best_train.shape[1]} out of {X_poly_train.shape[1]} features used\")\n",
    "print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "print('Reduced R-Squared: ', round(k_best_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another is `mutual_info_regression` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.48671803714022766\n",
      "Training Root Mean Squared Error: 54.993813733039715\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.3853213585946894\n",
      "Testing Root Mean Squared Error: 60.463957772103825\n",
      "\n",
      "----------------\n",
      "\n",
      "10 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.39\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(score_func=mutual_info_regression)\n",
    "X_k_best_train = selector.fit_transform(X_poly_train, y_train)\n",
    "X_k_best_test = selector.transform(X_poly_test)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_k_best_train, y_train)\n",
    "k_best_r2, k_best_rmse = run_model(lr, X_k_best_train, X_k_best_test, y_train, y_test)\n",
    "\n",
    "print('\\n----------------\\n')\n",
    "print(f\"{X_k_best_train.shape[1]} out of {X_poly_train.shape[1]} features used\")\n",
    "print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "print('Reduced R-Squared: ', round(k_best_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `f_regression` was more successful. Let's try that with some different values for `k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.22\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "11 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.41\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "21 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.38\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "31 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.38\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "41 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.38\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "51 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "61 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ks = np.arange(1, len(X_poly_train.columns), 10)\n",
    "reduced_r2s = []\n",
    "for k in ks:\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_k_best_train = selector.fit_transform(X_poly_train, y_train)\n",
    "    X_k_best_test = selector.transform(X_poly_test)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_k_best_train, y_train)\n",
    "    k_best_r2, k_best_rmse = run_model(lr, X_k_best_train, X_k_best_test, y_train, y_test, display=False)\n",
    "    reduced_r2s.append(k_best_r2)\n",
    "\n",
    "    print(f\"{k} out of {X_poly_train.shape[1]} features used\")\n",
    "    print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "    print('Reduced R-Squared: ', round(k_best_r2, 2))\n",
    "    print('\\n--------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(ks, reduced_r2s, label=\"features reduced with SelectKBest\")\n",
    "ax.axhline(y=poly_r2, linestyle=\"--\", label=\"baseline\")\n",
    "ax.set_xlabel(\"k\")\n",
    "ax.set_ylabel(\"Test R-Squared\")\n",
    "ax.legend(loc=\"lower right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the default `k` of 10 was pretty good! If we wanted to tune this further we would probably try some more values near 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Methods\n",
    "\n",
    "Now let's use recursive feature elimination (RFE) to try out a wrapper method. This method fits a model, assigns weights to features based on the model fit (in linear regression, these weights are the coefficients), and repeatedly removes the feature with the smallest weight until the desired fraction of features remains.\n",
    "\n",
    "Both this approach and the `SelectKBest` approach use both features and target. The difference is that `SelectKBest` computes a pairwise statistic for each feature vs. the target, whereas RFE actually fits the kind of model you are using.\n",
    "\n",
    "### `RFE`\n",
    "\n",
    "The `RFE` class from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) reduces the number of features down to 50% of the original features. Here it is in action: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.5342092420930167\n",
      "Training Root Mean Squared Error: 52.38793384069175\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.34884616712444305\n",
      "Testing Root Mean Squared Error: 62.232079108943836\n",
      "\n",
      "----------------\n",
      "\n",
      "32 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.35\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(LinearRegression())\n",
    "X_rfe_train = rfe.fit_transform(X_poly_train, y_train)\n",
    "X_rfe_test = rfe.transform(X_poly_test)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_rfe_train, y_train)\n",
    "\n",
    "rfe_r2, rfe_rmse = run_model(lr, X_rfe_train, X_rfe_test, y_train, y_test)\n",
    "print('\\n----------------\\n')\n",
    "print(f\"{X_rfe_train.shape[1]} out of {X_poly_train.shape[1]} features used\")\n",
    "print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "print('Reduced R-Squared: ', round(rfe_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also tune the number of features to select:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.35\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "11 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.37\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "21 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.32\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "31 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.35\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "41 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.35\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "51 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.37\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "61 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.36\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_ns = np.arange(1, len(X_poly_train.columns), 10)\n",
    "reduced_r2s = []\n",
    "for n in feature_ns:\n",
    "    rfe = RFE(LinearRegression(), n_features_to_select=n)\n",
    "    X_rfe_train = rfe.fit_transform(X_poly_train, y_train)\n",
    "    X_rfe_test = rfe.transform(X_poly_test)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_rfe_train, y_train)\n",
    "    rfe_r2, rfe_rmse = run_model(lr, X_rfe_train, X_rfe_test, y_train, y_test, display=False)\n",
    "    reduced_r2s.append(rfe_r2)\n",
    "\n",
    "    print(f\"{n} out of {X_poly_train.shape[1]} features used\")\n",
    "    print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "    print('Reduced R-Squared: ', round(rfe_r2, 2))\n",
    "    print('\\n--------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(feature_ns, reduced_r2s, label=\"features reduced with RFE\")\n",
    "ax.axhline(y=poly_r2, linestyle=\"--\", label=\"baseline\")\n",
    "ax.set_xlabel(\"n_features_to_select\")\n",
    "ax.set_ylabel(\"Test R-Squared\")\n",
    "ax.legend(loc=\"lower right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like sometimes `RFE` is able to get better metrics than the baseline polynomial model, but there is a lot of variance in the results.\n",
    "\n",
    "### `RFECV`\n",
    "\n",
    "A tool to address this kind of variance is `RFECV` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html)). The \"CV\" in the name stands for \"cross-validation\". This estimator fits _multiple_ models for each number of features, and thus also automatically selects an `n_features_to_select` value for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.5360295961081731\n",
      "Training Root Mean Squared Error: 52.28546514628111\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.3448128843695102\n",
      "Testing Root Mean Squared Error: 62.4245160429099\n",
      "\n",
      "----------------\n",
      "\n",
      "34 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.34\n"
     ]
    }
   ],
   "source": [
    "rfe_cv = RFECV(LinearRegression(), cv=15)\n",
    "X_rfe_train = rfe_cv.fit_transform(X_poly_train, y_train)\n",
    "X_rfe_test = rfe_cv.transform(X_poly_test)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_rfe_train, y_train)\n",
    "\n",
    "rfe_r2, rfe_rmse = run_model(lr, X_rfe_train, X_rfe_test, y_train, y_test)\n",
    "print('\\n----------------\\n')\n",
    "print(f\"{X_rfe_train.shape[1]} out of {X_poly_train.shape[1]} features used\")\n",
    "print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "print('Reduced R-Squared: ', round(rfe_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With recursive feature elimination, we went from an $R^2$ score of 0.36 to 0.38 (a tiny bit better). Let's see if we can improve upon these results even more by trying embedded methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Methods  \n",
    "\n",
    "To compare to our other methods, we will use lasso as the embedded method of feature selection. Luckily for us, `sklearn` has a built-in class `LassoCV` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)) to help us find the optimal features! It performs cross validation to determine the best regularization parameter (how much to penalize our function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.5796331222398328\n",
      "Training Root Mean Squared Error: 49.76798773972998\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2: 0.42197481285681393\n",
      "Testing Root Mean Squared Error: 58.63350974447024\n",
      "\n",
      "----------------\n",
      "\n",
      "The optimal alpha for the lasso regression is:  1.0793942862389214\n",
      "39 out of 65 features used\n",
      "Baseline R-Squared: 0.36\n",
      "Reduced R-Squared:  0.42\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(max_iter=10000, cv=15)\n",
    "\n",
    "lasso.fit(X_poly_train, y_train)\n",
    "lasso_r2, lasso_rmse = run_model(lasso, X_poly_train, X_poly_test, y_train, y_test)\n",
    "\n",
    "print('\\n----------------\\n')\n",
    "print('The optimal alpha for the lasso regression is: ', lasso.alpha_)\n",
    "print(f\"{sum(abs(lasso.coef_) < 10**(-10))} out of {X_poly_train.shape[1]} features used\")\n",
    "print('Baseline R-Squared:', round(poly_r2, 2))\n",
    "print('Reduced R-Squared: ', round(lasso_r2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the regularization had minimal effect on the performance of the model, but it did improve the metrics for the test set ever so slightly!\n",
    "\n",
    "There are no set steps someone should take in order to determine the optimal feature set. In fact, now there are automated machine learning pipelines that will determine the optimal subset of features for a given problem. One of the most important and often overlooked methods of feature selection is using domain knowledge about a given area to either eliminate features or create new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Feature Selection](https://www.researchgate.net/profile/Amparo_Alonso-Betanzos/publication/221252792_Filter_Methods_for_Feature_Selection_-_A_Comparative_Study/links/543fd9ec0cf21227a11b8e05.pdf)\n",
    "\n",
    "\n",
    "- [An Introduction to Variable and Feature Selection](http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This lesson formalized the different types of feature selection methods and introduced some new techniques to you. You learned about filter methods, wrapper methods, and embedded methods as well as their advantages and disadvantages. Then you saw how these methods can be applied using classes from scikit-learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
